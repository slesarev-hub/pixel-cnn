{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pixel-cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slesarev-hub/pixel-cnn/blob/master/pixel_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4Idcpd5QoS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install --ignore-installed --upgrade tensorflow==2.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvC-KKOsB0pT",
        "colab_type": "code",
        "outputId": "e0f171fc-e0fb-422b-ac01-80c70670fa44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python -c 'import tensorflow as tf; print(tf.__version__)' "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N83GAyLPTUvl",
        "colab_type": "code",
        "outputId": "245c80b9-98a5-4a15-adeb-513c4f02d132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!git clone https://github.com/slesarev-hub/pixel-cnn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "fatal: destination path 'pixel-cnn' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDDbhSrl4uro",
        "colab_type": "code",
        "outputId": "da5b695a-c14e-485d-ce0b-c48abbb04a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd pixel-cnn\n",
        "#!git checkout -b ahe 5de8cecf6c41b56f58cdd85d1aae1450c27673de"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pixel-cnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6MS0g5eYH9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train.py --data_dir . -d ahe -b 1 -u 1 -t 5 --load_params 80 --ckpt_folder_drive_dir '/content/drive/My Drive/pixel-cnn'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AovJdE8vNDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train.py --data_dir . -d ahe -b 1 -u 1 -t 5 --ckpt_folder_drive_dir '/content/drive/My Drive/pixel-cnn'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhYvQV9rTkKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 -c 'import tensorflow as tf; print(tf.__version__)'\n",
        "!python train.py --data_dir . --save_dir . -d ahe -b 1 -u 1 -t 5 -l 0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HArfhxK78Cfa",
        "colab_type": "text"
      },
      "source": [
        "**1.**\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/freeze/max/1000/1*ToPT8jnb5mtnikmiB42hpQ.png?q=20)\n",
        "\n",
        "**Softmax** (activation function)\n",
        "\n",
        "$\\sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}} \\text{ for } i = 1, \\dotsc , K \\text{ and } \\mathbf z=(z_1,\\dotsc,z_K) $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFbg8fWkI6ou",
        "colab_type": "text"
      },
      "source": [
        "**2.**\n",
        "\n",
        "**Softmax** - ignore relationship betwen numbers such as 220 and 221; even worse, if a pixel value never presents in the training dataset, it won’t be predicted in the testing dataset either. A better way is predict the distribution of pixel values, so every value will a have probility to present when generating images\n",
        "\n",
        " A mixture of distriction is a linear combination of a number of distributions: $p(x) = a_1 * p_1(x) + a_2 * p_2(x) + … a_n * p_n(x)$\n",
        "\n",
        "[source](https://medium.com/@smallfishbigsea/an-explanation-of-discretized-logistic-mixture-likelihood-bdfe531751f0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvLE1qpiVW7G",
        "colab_type": "text"
      },
      "source": [
        "![alt text](http://cs231n.github.io/assets/nn1/neuron_model.jpeg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xzw_s95ib5La",
        "colab_type": "text"
      },
      "source": [
        "**3.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB2MvbYsRpbZ",
        "colab_type": "text"
      },
      "source": [
        "![](https://stanford.edu/~shervine/teaching/cs-230/illustrations/convolution-layer-a.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd4kYuJKWrvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "http://cs231n.github.io/assets/conv-demo/index.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soUsUpcOZM2q",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "impractical to connect neurons to all neurons in the previous volume. Instead, we will connect each neuron to only a local region of the input volume. **Receptive field** of the neuron (equivalently this is the filter size)\n",
        "\n",
        "**Stride** - count of pixels which we slide the filter \n",
        "\n",
        "The most common **downsampling** operation is max, giving rise to max pooling, here shown with a stride of 2. That is, each max is taken over 4 numbers\n",
        "\n",
        "![alt text](http://cs231n.github.io/assets/cnn/maxpool.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnMQ59ryph2h",
        "colab_type": "text"
      },
      "source": [
        "**4.**\n",
        "\n",
        "**Layer types**\n",
        "\n",
        "*INPUT* - will hold the raw pixel values of the image\n",
        "\n",
        "*CONV* - compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to in the input volume. \n",
        "\n",
        "*RELU* - apply an elementwise activation function, leaves the size of the volume unchanged \n",
        "\n",
        "*POOL* - perform a **downsampling** operation along the spatial dimensions (width, height)\n",
        "\n",
        "*FC* - (i.e. fully-connected) compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score\n",
        "\n",
        "\n",
        "**RestNet**\n",
        "\n",
        "* with the network depth increasing, accuracy gets  saturated\n",
        "* explicitly let these layers fit a residual mapping (F(x)+x)\n",
        "\n",
        "![alt text](https://neurohive.io/wp-content/uploads/2019/01/resnet-e1548261477164.png)\n",
        "\n",
        "**PixelCNN++ scheme**\n",
        "\n",
        "6 blocks of 5 ResNet layers\n",
        "\n",
        "![alt text](https://asset-pdf.scinapse.io/prod/2581236139/figures/figure-2.jpg)\n",
        "\n",
        "**Deconvolution (upsampling)**\n",
        "\n",
        "possible ways:\n",
        "\n",
        "![](https://i.stack.imgur.com/YyCu2.gif)\n",
        "![](https://i.stack.imgur.com/f2RiP.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22xpF1We5vus",
        "colab_type": "text"
      },
      "source": [
        "**5.**\n",
        "\n",
        "**Droput**\n",
        "\n",
        "* given many more features than examples, linear models can overfit\n",
        "\n",
        "*  want to expect that adding some random noise to the pixels should be mostly harmless\n",
        "\n",
        "* when training deep network with many layers, enforcing smoothness just on the input-output mapping misses out on what is happening internally in the network [\\[Srivastava et al., 2014\\]](http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf)\n",
        "\n",
        "* Throughout training, on each iteration, dropout regularization consists simply of zeroing out some fraction of the nodes in each layer before calculating the subsequent layer\n",
        "\n",
        "![alt text](https://www.depends-on-the-definition.com/wp-content/uploads/2019/08/dropout.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-7uO0f3sEjX",
        "colab_type": "text"
      },
      "source": [
        "**PixelCNN++** vs **PixelCNN**\n",
        "\n",
        "*  Discretized logistic mixture likelihood (2) on the pixels, rather than a 256-way \n",
        "softmax (1), which we find to speed up training\n",
        "\n",
        "The standard PixelCNN model specifies the conditional distribution of a sub-pixel, or color channel\n",
        "of a pixel, as a full 256-way softmax. This gives the model a lot of flexibility, but it is also very costly\n",
        "in terms of memory.\n",
        "\n",
        "In PixelCNN++ assume there is\n",
        "a latent color intensity $\\nu$ with a continuous distribution, which is then rounded to its nearest 8-bit\n",
        "representation to give the observed sub-pixel value x. Distribution -  mixture of logistic distributions which allows us to easily calculate the probability on the observed discretized value x. For all sub-pixel values x excepting the edge cases 0 and 255 we have:\n",
        "\n",
        "$\\nu \\sim \\sum_{i=1}^K\\pi_ilogistic(\\mu_i, s_i)$\n",
        "\n",
        "$P(x|π, µ, s) = \\sum_{i=1}^K\\pi_i[\\sigma((x + 0.5 − \\mu_i)/s_i) − \\sigma((x − 0.5 − \\mu_i)/s_i)]$ \n",
        "\n",
        "$K = 5$\n",
        "\n",
        "*  Condition on whole pixels, rather than R/G/B sub-pixels,\n",
        "simplifying the model structure\n",
        "\n",
        "PixelCNN factorizes the generative model over 3 sub-pixels. This\n",
        "allows for very general dependency structure. \n",
        "PixelCNN++:\n",
        "  \n",
        "$~~$firstly predict the red channel using a discretized mixture of logistics as described before\n",
        "\n",
        "\n",
        "$~~$secondly predict the green channel using a predictive distribution of the\n",
        "same form. Here we allow the means of the mixture components to linearly depend on the value of\n",
        "the red sub-pixel\n",
        "\n",
        "$~~$finally model the blue channel in the same way, where we again only allow linear dependency on the red and green channels.\n",
        "*  Use downsampling to efficiently capture\n",
        "structure at multiple resolutions\n",
        "\n",
        "*  Introduce additional short-cut connections to further speed up optimization\n",
        "\n",
        "*PixelCNN* only uses convolutions with small **receptive field** (3) (good at capturing local dependencies, but not at modeling long range structure).\n",
        "\n",
        "*PixelCNN++* to model whole structure - use **downsampling** by using convolutions of **stride** $2$. (loses information, but can compensate for this by introducing additional short-cut connections\n",
        "into the network)\n",
        "\n",
        "*  Regularize the model using dropout\n",
        "\n",
        "In *PixelCNN++* - standard binary dropout on the residual path after the first\n",
        "convolution"
      ]
    }
  ]
}